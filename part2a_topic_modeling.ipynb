{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "SCRIPT_PATH = pathlib.Path.cwd()\n",
    "\n",
    "OUTPUT_PATH = SCRIPT_PATH.joinpath('part2a_output')\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUT_PATH = SCRIPT_PATH.joinpath('part2a_input')\n",
    "INPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# MALLET_PATH = SCRIPT_PATH.joinpath('mallet/bin/mallet')\n",
    "MALLET_PATH = SCRIPT_PATH.joinpath('/srv/mallet/bin/mallet')\n",
    "\n",
    "print('Script path: {}'.format(str(SCRIPT_PATH)))\n",
    "print('Output path: {}'.format(str(OUTPUT_PATH)))\n",
    "print('Input path: {}'.format(str(INPUT_PATH)))\n",
    "print('MALLET path: {}'.format(str(MALLET_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/Wikipedia-API/\n",
    "\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://en.wikipedia.org/api/rest_v1/page/html/List_of_fields_of_doctoral_studies_in_the_United_States\"\n",
    "\n",
    "####################################################################\n",
    "\n",
    "links_source_html = ''\n",
    "\n",
    "with request.urlopen(URL) as f:\n",
    "    links_source_html = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "source_links = [source_link.get('href') \n",
    "                for source_link in links_source_html.select('.mw-redirect') \n",
    "                if ('#' not in source_link.get('href')\n",
    "                    and ('List_of_fields_of_doctoral_studies_in_the_United_States' not in source_link.get('href'))\n",
    "                    and (source_link.get('href').startswith('./')))]\n",
    "\n",
    "source_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_links = source_links[2:-3]\n",
    "source_links = set(source_links)\n",
    "source_links = [source_link[2:] for source_link in source_links]\n",
    "\n",
    "len(source_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ROOT_URL = \"https://en.wikipedia.org/api/rest_v1/page/html/\"\n",
    "\n",
    "for source_link in source_links:\n",
    "    paragraphs = []\n",
    "    with request.urlopen(API_ROOT_URL + source_link) as f:\n",
    "        target_html = BeautifulSoup(f, 'html.parser')\n",
    "        for paragraph in target_html.select('p'):\n",
    "            word_count = len(paragraph.get_text().split())\n",
    "            if word_count < 5:\n",
    "                continue\n",
    "            else:\n",
    "                paragraphs.append(paragraph.get_text())\n",
    "                \n",
    "    text_path = INPUT_PATH.joinpath(source_link + '.txt')\n",
    "    with open(text_path, 'w+') as f:\n",
    "        f.write(' '.join(paragraphs))\n",
    "        print('Saved to {}.'.format(text_path.parts[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_filenames = [str(file)\n",
    "                        for file in INPUT_PATH.iterdir()\n",
    "                        if file.suffix == '.txt']\n",
    "    \n",
    "input_text_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "data = []\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "for input_text_filename in input_text_filenames:\n",
    "    with open(input_text_filename, 'r') as f:\n",
    "        words = gensim.utils.simple_preprocess(f.read(), deacc=True)\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        data.append(words)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = gensim.corpora.Dictionary(data)\n",
    "corpus = [id2word.doc2bow(document) for document in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.wrappers.LdaMallet(mallet_path=str(MALLET_PATH), \n",
    "                                         corpus=corpus,\n",
    "                                         num_topics=20,\n",
    "                                         id2word=id2word,\n",
    "                                         optimize_interval=10,\n",
    "                                         iterations=100,\n",
    "                                         random_seed=20190923)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.show_topics(num_topics=20, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(str(OUTPUT_PATH.joinpath('mallet_output')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.read_doctopics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = list(model.get_topics())\n",
    "document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ftopickeys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /var/folders/80/2t7ffq3n05n2jcz8p2500h0m0000gn/T/caf971_topickeys.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
